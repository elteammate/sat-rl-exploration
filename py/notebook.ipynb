{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:20.046597Z",
     "start_time": "2024-12-06T18:12:20.038527Z"
    }
   },
   "source": [
    "from torch_geometric.data import Data\n",
    "from tensordict import TensorDict\n",
    "import torch_geometric.nn as gnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "import torch.functional as F\n",
    "import torchrl.envs\n",
    "import torchrl.modules\n",
    "import torchrl.objectives\n",
    "import networkx as nx\n",
    "import pyvis\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import runner\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Protocol, cast\n",
    "import enum\n",
    "import dataclasses\n",
    "import pickle\n",
    "import asyncio\n",
    "import random\n",
    "import json\n",
    "import logging"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:20.101149Z",
     "start_time": "2024-12-06T18:12:20.093515Z"
    }
   },
   "source": [
    "logger = logging.getLogger(\"notebook\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:20.155750Z",
     "start_time": "2024-12-06T18:12:20.146442Z"
    }
   },
   "source": [
    "from primitives import Clause\n",
    "\n",
    "class NodeType(enum.Enum):\n",
    "    VARIABLE = 0\n",
    "    REDUNDANT = 1\n",
    "    IRREDUNDANT = 2\n",
    "\n",
    "class CnfGraph(Protocol):\n",
    "    global_data: torch.Tensor\n",
    "    x: torch.Tensor\n",
    "    edge_index: torch.Tensor\n",
    "    edge_attr: torch.Tensor\n",
    "    node_type: torch.Tensor\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class DimInfo:\n",
    "    num_global_features: int\n",
    "    num_var_features: int\n",
    "    num_clause_features: int\n",
    "    num_edge_features: int\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class ReductionProblem:\n",
    "    num_vars: int\n",
    "    levels: list[int]\n",
    "    vals: list[int]\n",
    "    clauses: list[Clause]\n",
    "    reducible_ids: list[int]"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:20.219371Z",
     "start_time": "2024-12-06T18:12:20.201037Z"
    }
   },
   "source": [
    "def problem_to_cnf_graph(problem: ReductionProblem) -> tuple[CnfGraph, DimInfo]:\n",
    "    logger.info(\"Converting problem to CNF graph\")\n",
    "    num_vars = problem.num_vars\n",
    "\n",
    "    fixed_vals = [problem.vals[i] if problem.levels[i] == 0 else 0 for i in range(num_vars)]\n",
    "\n",
    "    clauses = []\n",
    "    for clause in problem.clauses:\n",
    "        new_lits = []\n",
    "        for lit in clause.lits:\n",
    "            v = abs(lit) - 1\n",
    "            if fixed_vals[v] == 0:\n",
    "                new_lits.append(lit)\n",
    "            elif lit > 0 and fixed_vals[v] == 1 or lit < 0 and fixed_vals[v] == -1:\n",
    "                break\n",
    "            # else skip literal because it's falsified\n",
    "        else:\n",
    "            clauses.append(clause.with_lits(new_lits))\n",
    "\n",
    "    num_clauses = len(clauses)\n",
    "    num_free_vars = sum(1 for v in fixed_vals if v == 0)\n",
    "\n",
    "    c_clause_sizes = np.array([len(clause.lits) for clause in clauses])\n",
    "    c_clause_lbd = np.array([clause.lbd for clause in clauses])\n",
    "    g_max_clause_size = c_clause_sizes.max()\n",
    "    g_min_clause_size = c_clause_sizes.min()\n",
    "    g_mean_clause_size = c_clause_sizes.mean()\n",
    "    g_min_clause_lbd = c_clause_lbd.min()\n",
    "    g_max_clause_lbd = c_clause_lbd.max()\n",
    "    g_lbd_spread = g_max_clause_lbd - g_min_clause_lbd\n",
    "    g_mean_clause_lbd = c_clause_lbd.mean()\n",
    "    c_lbd_size_ratio = c_clause_lbd / c_clause_sizes\n",
    "    c_num_pos_literals = np.array([sum(1 for lit in clause.lits if lit > 0) for clause in clauses])\n",
    "    c_num_neg_literals = c_clause_sizes - c_num_pos_literals\n",
    "    c_pos_neg_ratios = c_num_pos_literals / c_clause_sizes\n",
    "    g_max_pos_neg_ratio = c_pos_neg_ratios.max()\n",
    "    g_min_pos_neg_ratio = c_pos_neg_ratios.min()\n",
    "    g_mean_pos_neg_ratio = c_pos_neg_ratios.mean()\n",
    "    c_horn = c_num_pos_literals <= 1\n",
    "    g_horn_ratio = c_horn.mean()\n",
    "    c_inv_horn = c_num_neg_literals <= 1\n",
    "    g_inv_horn_ratio = c_inv_horn.mean()\n",
    "    g_size_spread = g_max_clause_size - g_min_clause_size\n",
    "    g_pos_neg_ratio_spread = g_max_pos_neg_ratio - g_min_pos_neg_ratio\n",
    "\n",
    "    v_pos = np.zeros(num_vars)\n",
    "    v_neg = np.zeros(num_vars)\n",
    "    v_horn = np.zeros(num_vars)\n",
    "    v_invhorn = np.zeros(num_vars)\n",
    "\n",
    "    for i, clause in enumerate(clauses):\n",
    "        for lit in clause.lits:\n",
    "            v = abs(lit) - 1\n",
    "            if lit > 0:\n",
    "                v_pos[v] += 1\n",
    "            else:\n",
    "                v_neg[v] += 1\n",
    "            if c_horn[i]:\n",
    "                v_horn[v] += 1\n",
    "            if c_inv_horn[i]:\n",
    "                v_invhorn[v] += 1\n",
    "\n",
    "    v_count = v_pos + v_neg\n",
    "    v_pos_neg_ratios = v_pos / v_count\n",
    "    v_horn_ratio = v_horn / v_count\n",
    "    v_invhorn_ratio = v_invhorn / v_count\n",
    "    g_var_horn_min = v_horn.min()\n",
    "    g_var_horn_max = v_horn.max()\n",
    "    g_var_horn_mean = v_horn.mean()\n",
    "    g_var_invhorn_min = v_invhorn.min()\n",
    "    g_var_invhorn_max = v_invhorn.max()\n",
    "    g_var_invhorn_mean = v_invhorn.mean()\n",
    "    g_var_horn_std = v_horn.std()\n",
    "    g_var_invhorn_std = v_invhorn.std()\n",
    "    g_var_pos_neg_ratio_std = v_pos_neg_ratios.std()\n",
    "    g_var_count_std = v_count.std()\n",
    "    g_var_clause_ratio = num_free_vars / num_clauses\n",
    "    g_free_ratio = num_free_vars / num_vars\n",
    "\n",
    "    c_clause_keep = np.array([clause.keep for clause in clauses])\n",
    "    c_clause_redundant = np.array([clause.redundant for clause in clauses])\n",
    "\n",
    "    global_features = [\n",
    "        g_mean_clause_size,\n",
    "        g_mean_clause_lbd,\n",
    "        g_mean_pos_neg_ratio,\n",
    "        g_horn_ratio,\n",
    "        g_inv_horn_ratio,\n",
    "        g_var_horn_mean,\n",
    "        g_var_invhorn_mean,\n",
    "        g_var_horn_std,\n",
    "        g_var_invhorn_std,\n",
    "        g_var_pos_neg_ratio_std,\n",
    "        g_var_count_std,\n",
    "        g_var_clause_ratio,\n",
    "        g_free_ratio,\n",
    "    ]\n",
    "\n",
    "    clause_features = [\n",
    "        c_clause_sizes,\n",
    "        c_clause_sizes / num_vars,\n",
    "        (c_clause_sizes - g_min_clause_size) / g_size_spread if g_size_spread > 0 else 0,\n",
    "        c_clause_lbd,\n",
    "        (c_clause_lbd - g_min_clause_lbd) / g_lbd_spread if g_lbd_spread > 0 else 0,\n",
    "        c_lbd_size_ratio,\n",
    "        c_pos_neg_ratios,\n",
    "        c_horn,\n",
    "        c_inv_horn,\n",
    "        c_clause_redundant,\n",
    "        c_clause_keep,\n",
    "    ]\n",
    "\n",
    "    var_features = [\n",
    "        v_pos,\n",
    "        v_neg,\n",
    "        v_pos_neg_ratios,\n",
    "        v_horn,\n",
    "        v_invhorn,\n",
    "        v_horn_ratio,\n",
    "        v_invhorn_ratio,\n",
    "    ]\n",
    "\n",
    "    embedding_size = max(len(var_features), len(clause_features))\n",
    "\n",
    "    global_data = torch.tensor(global_features, dtype=torch.float32)\n",
    "    x = torch.zeros(num_free_vars + num_clauses, embedding_size)\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    node_type = torch.zeros(num_vars + num_clauses, dtype=torch.int8)\n",
    "\n",
    "    node_type[:num_vars] = NodeType.VARIABLE.value\n",
    "    node_type[num_vars:] = NodeType.IRREDUNDANT.value\n",
    "\n",
    "    reducible_ids = set(problem.reducible_ids)\n",
    "\n",
    "    for i, clause in enumerate(clauses):\n",
    "        if clause.id_ in reducible_ids:\n",
    "            node_type[num_vars + i] = NodeType.REDUNDANT.value\n",
    "\n",
    "    for i, f in enumerate(var_features):\n",
    "        x[:num_vars, i] = torch.tensor(f, dtype=torch.float32)\n",
    "\n",
    "    for i, f in enumerate(clause_features):\n",
    "        x[num_vars:, i] = torch.tensor(f, dtype=torch.float32)\n",
    "\n",
    "    for i, clause in enumerate(clauses):\n",
    "        for lit in clause.lits:\n",
    "            v = abs(lit) - 1\n",
    "            edge_index.append((v, num_vars + i))\n",
    "            edge_attr.append(-1 if lit < 0 else 1)\n",
    "\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    logger.info(\"Finished converting problem to CNF graph\")\n",
    "\n",
    "    return cast(CnfGraph, Data(\n",
    "        global_data=global_data,\n",
    "        x=x,\n",
    "        edge_index=torch.tensor(edge_index, dtype=torch.int64).t(),\n",
    "        edge_attr=edge_attr,\n",
    "        node_type=node_type,\n",
    "    )), DimInfo(\n",
    "        num_clause_features=len(clause_features),\n",
    "        num_edge_features=edge_attr.size(dim=1),\n",
    "        num_global_features=len(global_features),\n",
    "        num_var_features=len(var_features),\n",
    "    )\n",
    "\n",
    "\n",
    "def ordered_reducible_ids(problem: ReductionProblem) -> list[int]:\n",
    "    reducible_ids = set(problem.reducible_ids)\n",
    "    return [clause.id_ for clause in problem.clauses if clause.id_ in reducible_ids]"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:20.267373Z",
     "start_time": "2024-12-06T18:12:20.263774Z"
    }
   },
   "source": [
    "minimal_example_data, DIM_INFO = problem_to_cnf_graph(ReductionProblem(\n",
    "    2,\n",
    "    [1, 1],\n",
    "    [0, 0],\n",
    "    [\n",
    "        Clause(0, [1, 2], 0, False, True, False),\n",
    "        Clause(5, [-1, -2], 0, False, False, False),\n",
    "        Clause(8, [-1, 2], 0, False, False, False),\n",
    "    ],\n",
    "    [5, 8],\n",
    "))\n",
    "\n",
    "print(DIM_INFO)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:notebook:Converting problem to CNF graph\n",
      "INFO:notebook:Finished converting problem to CNF graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DimInfo(num_global_features=13, num_var_features=7, num_clause_features=11, num_edge_features=1)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.179578Z",
     "start_time": "2024-12-06T18:12:20.320959Z"
    }
   },
   "source": [
    "with open(\"../archives/example-problem.pkl\", \"rb\") as f:\n",
    "    problem = pickle.load(f)\n",
    "\n",
    "example_data, _ = problem_to_cnf_graph(problem)\n",
    "\n",
    "nx_graph = torch_geometric.utils.to_networkx(example_data, to_undirected=True)\n",
    "\n",
    "g = pyvis.network.Network(width=1800, height=1000, cdn_resources='in_line')\n",
    "g.toggle_hide_edges_on_drag = True\n",
    "g.barnes_hut()\n",
    "g.from_nx(nx_graph)\n",
    "g.save_graph(\"example.html\")\n",
    "\n",
    "eccentricities = list(nx.eccentricity(nx_graph).values())\n",
    "plt.bar(*np.unique(eccentricities, return_counts=True))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:notebook:Converting problem to CNF graph\n",
      "INFO:notebook:Finished converting problem to CNF graph\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.187747Z",
     "start_time": "2024-12-06T18:12:23.185421Z"
    }
   },
   "source": [
    "class CnfProcessingBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, edge_dim: int, disambiguate_clauses: bool):\n",
    "        super().__init__()\n",
    "\n",
    "        self.disambiguate_clauses = disambiguate_clauses\n",
    "\n",
    "        if disambiguate_clauses:\n",
    "            self.conv_redundant = gnn.GATv2Conv(in_channels, out_channels, edge_dim=edge_dim, residual=True)\n",
    "            self.conv_irredundant = gnn.GATv2Conv(in_channels, out_channels, edge_dim=edge_dim, residual=True)\n",
    "        else:\n",
    "            self.conv_clauses = gnn.GATv2Conv(in_channels, out_channels, edge_dim=edge_dim, residual=True)\n",
    "\n",
    "        self.conv_variables = gnn.GATv2Conv(in_channels, out_channels, edge_dim=edge_dim, residual=True)\n",
    "\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, h, data):\n",
    "        edge_index, edge_attr, node_type = data.edge_index, data.edge_attr, data.node_type\n",
    "\n",
    "        out = torch.zeros_like(h)\n",
    "\n",
    "        variable_mask = (node_type == NodeType.VARIABLE.value)\n",
    "        out[variable_mask, :] = self.conv_variables(h, edge_index, edge_attr)[variable_mask, :]\n",
    "\n",
    "        if self.disambiguate_clauses:\n",
    "            redundant_mask = (node_type == NodeType.REDUNDANT.value)\n",
    "            irredundant_mask = (node_type == NodeType.IRREDUNDANT.value)\n",
    "\n",
    "            out[redundant_mask, :] = self.conv_redundant(h, edge_index, edge_attr)[redundant_mask, :]\n",
    "            out[irredundant_mask, :] = self.conv_irredundant(h, edge_index, edge_attr)[irredundant_mask, :]\n",
    "        else:\n",
    "            clause_mask = (node_type != NodeType.VARIABLE.value)\n",
    "\n",
    "            out[clause_mask] = self.conv_clauses(h, edge_index, edge_attr)[clause_mask, :]\n",
    "\n",
    "\n",
    "        out = self.activation(out)\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.247059Z",
     "start_time": "2024-12-06T18:12:23.238620Z"
    }
   },
   "source": [
    "class ExpectedValueNormalization(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, p: torch.Tensor, ex: torch.Tensor):\n",
    "        ex = torch.as_tensor(ex)\n",
    "\n",
    "        gamma = torch.ones(p.shape[:-1], device=p.device)\n",
    "\n",
    "        for _ in range(6):\n",
    "            normalized = p ** gamma.unsqueeze(-1)\n",
    "            f_gamma = normalized.sum(dim=-1) - ex\n",
    "            f_prime_gamma = (normalized * p.log()).sum(dim=-1)\n",
    "            gamma = gamma - f_gamma / f_prime_gamma\n",
    "\n",
    "        normalized = p ** gamma.unsqueeze(-1)\n",
    "        ctx.save_for_backward(p, normalized, gamma)\n",
    "        return normalized\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        p, normalized, gamma = ctx.saved_tensors\n",
    "\n",
    "        normalized_dp = normalized * p.log()\n",
    "        denom = normalized_dp.sum(dim=-1)\n",
    "\n",
    "        jac = (\n",
    "            torch.diag_embed(gamma.unsqueeze(-1) * normalized / p) -\n",
    "            (gamma / denom).unsqueeze(-1).unsqueeze(-1) * normalized_dp.unsqueeze(-2) * (normalized / p).unsqueeze(-1)\n",
    "        )\n",
    "\n",
    "        return (jac @ grad_output.unsqueeze(-1)).squeeze(-1), None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "x = torch.tensor([\n",
    "    [1., 0.5, 0.5, 0.5, 0.1],\n",
    "    [0.3, 0.5, 0.5, 0.8, 0.2],\n",
    "], requires_grad=True)\n",
    "optim = torch.optim.SGD([x], lr=0.1)\n",
    "for _ in range(100):\n",
    "    optim.zero_grad()\n",
    "    y = ExpectedValueNormalization.apply(x, torch.tensor([2.0, 1.0]))\n",
    "    loss = y.pow(3.0).sum()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    print(x.sum(axis=1))\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx = torch.tensor([\\n    [1., 0.5, 0.5, 0.5, 0.1],\\n    [0.3, 0.5, 0.5, 0.8, 0.2],\\n], requires_grad=True)\\noptim = torch.optim.SGD([x], lr=0.1)\\nfor _ in range(100):\\n    optim.zero_grad()\\n    y = ExpectedValueNormalization.apply(x, torch.tensor([2.0, 1.0]))\\n    loss = y.pow(3.0).sum()\\n    loss.backward()\\n    optim.step()\\n    print(x.sum(axis=1))\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.274452Z",
     "start_time": "2024-12-06T18:12:23.269674Z"
    }
   },
   "source": [
    "class CnfGraphModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_global_dim: int,\n",
    "        input_variable_dim: int,\n",
    "        input_clause_dim: int,\n",
    "        hidden_dims: list[int],\n",
    "        disambiguate_clauses_in_first: int = 2,\n",
    "        edge_dim: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_variable_dim = input_variable_dim\n",
    "        self.input_clause_dim = input_clause_dim\n",
    "\n",
    "        self.variable_fc = nn.Linear(input_global_dim + input_variable_dim, hidden_dims[0])\n",
    "        self.clause_fc = nn.Linear(input_global_dim + input_clause_dim, hidden_dims[0])\n",
    "\n",
    "        self.silu = nn.SiLU()\n",
    "\n",
    "        self.processing_blocks = nn.ModuleList([\n",
    "            CnfProcessingBlock(\n",
    "                hidden_dims[i],\n",
    "                hidden_dims[i + 1],\n",
    "                edge_dim,\n",
    "                i < disambiguate_clauses_in_first\n",
    "            )\n",
    "            for i in range(len(hidden_dims) - 1)\n",
    "        ])\n",
    "\n",
    "        self.output_fc = nn.Linear(hidden_dims[-1], 1)\n",
    "\n",
    "        self.value_fc_clauses = nn.Linear(hidden_dims[-1], 1)\n",
    "        self.value_fc_variables = nn.Linear(hidden_dims[-1], 1)\n",
    "\n",
    "    def forward(self, cnf_graph: CnfGraph, ex: torch.Tensor | float):\n",
    "        logger.info(\"Starting model forward pass\")\n",
    "\n",
    "        num_vertices = cnf_graph.x.shape[0]\n",
    "        variable_mask = (cnf_graph.node_type == NodeType.VARIABLE.value)\n",
    "        num_variables = variable_mask.sum()\n",
    "\n",
    "        variable_input = torch.cat([\n",
    "            cnf_graph.global_data.expand(num_variables, -1),\n",
    "            cnf_graph.x[:num_variables, :self.input_variable_dim],\n",
    "        ], dim=-1)\n",
    "\n",
    "        variable_embedding = self.silu(self.variable_fc(variable_input))\n",
    "\n",
    "        clause_input = torch.cat([\n",
    "            cnf_graph.global_data.expand(num_vertices - num_variables, -1),\n",
    "            cnf_graph.x[num_variables:, :self.input_clause_dim],\n",
    "        ], dim=-1)\n",
    "\n",
    "        clause_embedding = self.silu(self.clause_fc(clause_input))\n",
    "\n",
    "        x = torch.cat([variable_embedding, clause_embedding], dim=0)\n",
    "\n",
    "        for block in self.processing_blocks:\n",
    "            x = block(x, cnf_graph)\n",
    "\n",
    "        logits = self.output_fc(x[cnf_graph.node_type == NodeType.REDUNDANT.value]).view(-1)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        probs = ExpectedValueNormalization.apply(probs, ex)\n",
    "\n",
    "        value_vars = self.value_fc_variables(x[variable_mask])\n",
    "        value_clauses = self.value_fc_clauses(x[~variable_mask])\n",
    "        value = torch.cat([value_vars, value_clauses]).mean()\n",
    "\n",
    "        logger.info(\"Finished model forward pass\")\n",
    "\n",
    "        return probs, value"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.353635Z",
     "start_time": "2024-12-06T18:12:23.327971Z"
    }
   },
   "source": [
    "testing_model = CnfGraphModel(\n",
    "    input_global_dim=DIM_INFO.num_global_features,\n",
    "    input_variable_dim=DIM_INFO.num_var_features,\n",
    "    input_clause_dim=DIM_INFO.num_clause_features,\n",
    "    edge_dim=DIM_INFO.num_edge_features,\n",
    "    hidden_dims=[32, 32, 32, 32],\n",
    ")\n",
    "\n",
    "testing_model(minimal_example_data, 0.75)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.3756, 0.3744], grad_fn=<ExpectedValueNormalizationBackward>),\n",
       " tensor(-0.1659, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.394889Z",
     "start_time": "2024-12-06T18:12:23.392182Z"
    }
   },
   "source": [
    "DEV = \"cpu\"\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.439667Z",
     "start_time": "2024-12-06T18:12:23.437346Z"
    }
   },
   "source": [
    "@dataclasses.dataclass\n",
    "class Hyperparameters:\n",
    "    batch_size: int = 64\n",
    "    learning_rate: float = 3e-4\n",
    "    epochs: int = 4\n",
    "    eps_clip: float = 0.2\n",
    "    entropy_coef: float = 0.01\n",
    "    value_weight: float = 0.5\n",
    "    policy_weight: float = 1.0\n",
    "    gae_gamma: float = 0.99\n",
    "    gae_lambda: float = 0.95\n",
    "    penalty_per_conflict: float = 5e-4\n",
    "\n",
    "\n",
    "HP = Hyperparameters()\n"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.483661Z",
     "start_time": "2024-12-06T18:12:23.481322Z"
    }
   },
   "source": [
    "def compute_returns_advantages(rewards: list[float], values: list[float]) -> tuple[list[float], list[float]]:\n",
    "    returns = []\n",
    "    advantages = []\n",
    "    gae = 0\n",
    "    for i in reversed(range(len(rewards))):\n",
    "        delta = rewards[i] + HP.gae_gamma * (values[i + 1] if i + 1 < len(values) else 0) - values[i]\n",
    "        gae = delta + HP.gae_gamma * HP.gae_lambda * gae\n",
    "        returns.append(gae + values[i])\n",
    "        advantages.append(gae)\n",
    "    return returns[::-1], advantages[::-1]"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.533943Z",
     "start_time": "2024-12-06T18:12:23.528766Z"
    }
   },
   "source": [
    "@dataclasses.dataclass\n",
    "class EpisodeResult:\n",
    "    states: list[CnfGraph]\n",
    "    dists: list[torch.distributions.Bernoulli]\n",
    "    actions: list[torch.Tensor]\n",
    "    rewards: list[float]\n",
    "    values: list[float]\n",
    "    returns: list[float]\n",
    "    advantages: list[float]\n",
    "\n",
    "    stats: list[dict]\n",
    "\n",
    "    @staticmethod\n",
    "    def empty() -> 'EpisodeResult':\n",
    "        return EpisodeResult([], [], [], [], [], [], [], [])\n",
    "\n",
    "    def merge_with(self, other: 'EpisodeResult') -> 'EpisodeResult':\n",
    "        assert (\n",
    "            len(self.states) == len(self.dists) == len(self.actions) ==\n",
    "            len(self.values) == len(self.rewards) == len(self.returns) ==\n",
    "            len(self.advantages)\n",
    "        )\n",
    "        assert (\n",
    "            len(other.states) == len(other.dists) == len(other.actions) ==\n",
    "            len(other.values) == len(other.rewards) == len(other.returns) ==\n",
    "            len(other.advantages)\n",
    "        )\n",
    "        return EpisodeResult(\n",
    "            self.states + other.states,\n",
    "            self.dists + other.dists,\n",
    "            self.actions + other.actions,\n",
    "            self.rewards + other.rewards,\n",
    "            self.values + other.values,\n",
    "            self.returns + other.returns,\n",
    "            self.advantages + other.advantages,\n",
    "            self.stats + other.stats,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_all(results: list['EpisodeResult']) -> 'EpisodeResult':\n",
    "        result = results[0]\n",
    "        for other in results[1:]:\n",
    "            result = result.merge_with(other)\n",
    "        return result\n",
    "\n",
    "    def add(self, *, state, dist, action, reward, value):\n",
    "        assert (\n",
    "            len(self.states) == len(self.dists) == len(self.actions) ==\n",
    "            len(self.values) == len(self.rewards)\n",
    "        )\n",
    "        self.states.append(state)\n",
    "        self.dists.append(dist)\n",
    "        self.actions.append(action)\n",
    "        if reward is not None:\n",
    "            self.rewards.append(reward)\n",
    "        self.values.append(value)\n",
    "\n",
    "    def add_reward(self, reward):\n",
    "        assert (\n",
    "            len(self.states) == len(self.dists) == len(self.actions) ==\n",
    "            len(self.values) == len(self.rewards) + 1\n",
    "        )\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    def complete(self, stats: dict):\n",
    "        assert (\n",
    "            len(self.states) == len(self.dists) == len(self.actions) ==\n",
    "            len(self.values) == len(self.rewards)\n",
    "        )\n",
    "        assert len(self.stats) == 0\n",
    "        self.returns, self.advantages = compute_returns_advantages(self.rewards, self.values)\n",
    "        self.stats = [stats]\n"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.587158Z",
     "start_time": "2024-12-06T18:12:23.577306Z"
    }
   },
   "source": [
    "class Agent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model.to(DEV)\n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=HP.learning_rate)\n",
    "\n",
    "    def act(self, cnf_graph: CnfGraph, ex: float):\n",
    "        logger.info(\"Running agent act\")\n",
    "        with torch.no_grad():\n",
    "            cnf_graph = cnf_graph.to(DEV)\n",
    "            probs, value = self.model(cnf_graph, ex)\n",
    "            logger.info(\"Finished agent act\")\n",
    "            return torch.distributions.Bernoulli(probs), value.item()\n",
    "\n",
    "    def update(self, results: EpisodeResult):\n",
    "        logger.info(\"Training agent\")\n",
    "        assert all(a.dtype == torch.bool for a in results.actions)\n",
    "        r = results\n",
    "\n",
    "        n = len(r.states)\n",
    "        batch_size = HP.batch_size\n",
    "        for num_epoch in range(HP.epochs):\n",
    "            logger.info(\"Training agent, epoch %d\", num_epoch)\n",
    "            indices = random.sample(range(n), n)\n",
    "            for batch_start in range(0, n, batch_size):\n",
    "                idx = indices[batch_start:batch_start + batch_size]\n",
    "\n",
    "                self.optim.zero_grad()\n",
    "                for i in idx:\n",
    "                    graph, ex = r.states[i]\n",
    "                    new_probs, value = self.model(graph, ex)\n",
    "                    value = value.cpu()\n",
    "                    dist = torch.distributions.Bernoulli(probs=new_probs)\n",
    "                    log_probs = dist.log_prob(r.actions[i].float())\n",
    "                    entropy = dist.entropy().sum()\n",
    "\n",
    "                    ratio = torch.exp(log_probs - r.dists[i].log_prob(r.actions[i].float()))\n",
    "                    surr1 = ratio * r.advantages[i]\n",
    "                    surr2 = torch.clamp(ratio, 1.0 - HP.eps_clip, 1.0 + HP.eps_clip) * r.advantages[i]\n",
    "\n",
    "                    value_loss = torch.nn.functional.mse_loss(value, torch.tensor(r.rewards[i] + r.values[i]))\n",
    "                    policy_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "                    loss = (\n",
    "                        HP.policy_weight * policy_loss\n",
    "                        + HP.value_weight * value_loss\n",
    "                        - HP.entropy_coef * entropy\n",
    "                    ) / len(idx)\n",
    "\n",
    "                    loss.backward()\n",
    "\n",
    "                self.optim.step()"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.798890Z",
     "start_time": "2024-12-06T18:12:23.643947Z"
    }
   },
   "source": [
    "testing_agent = Agent(testing_model)\n",
    "\n",
    "states = [\n",
    "    (minimal_example_data, 0.75),\n",
    "    (minimal_example_data, 0.5),\n",
    "    (minimal_example_data, 0.25),\n",
    "]\n",
    "\n",
    "dist1, value1 = testing_agent.act(*states[0])\n",
    "dist2, value2 = testing_agent.act(*states[1])\n",
    "dist3, value3 = testing_agent.act(*states[2])\n",
    "\n",
    "dists = [dist1, dist2, dist3]\n",
    "values = [value1, value2, value3]\n",
    "print(values)\n",
    "\n",
    "actions = [dist.sample() > 0.5 for dist in dists]\n",
    "rewards = [-1.0, -1.0, 10.0]\n",
    "\n",
    "returns, advantages = compute_returns_advantages(rewards, [1.0, 1.0, 1.0])\n",
    "print(advantages)\n",
    "\n",
    "results = EpisodeResult(\n",
    "    states,\n",
    "    dists,\n",
    "    actions,\n",
    "    rewards,\n",
    "    values,\n",
    "    returns,\n",
    "    advantages,\n",
    "    [],\n",
    ")\n",
    "\n",
    "testing_agent.update(results)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:notebook:Running agent act\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Finished agent act\n",
      "INFO:notebook:Running agent act\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Finished agent act\n",
      "INFO:notebook:Running agent act\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Finished agent act\n",
      "INFO:notebook:Training agent\n",
      "INFO:notebook:Training agent, epoch 0\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Starting model forward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16592970490455627, -0.16592970490455627, -0.16592970490455627]\n",
      "[6.00095725, 7.4544999999999995, 9.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Training agent, epoch 1\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Training agent, epoch 2\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Training agent, epoch 3\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.981565Z",
     "start_time": "2024-12-06T18:12:23.807765Z"
    }
   },
   "source": [
    "@dataclasses.dataclass\n",
    "class CnfProblemInstance:\n",
    "    result: bool\n",
    "    path: Path\n",
    "    stats: dict[str, any]\n",
    "    stats_no_reductions: dict[str, any]\n",
    "\n",
    "\n",
    "with open(\"../archives/runs.json\", \"r\") as f:\n",
    "    runs = [json.loads(line) for line in f.readlines()]\n",
    "    runs = [CnfProblemInstance(\n",
    "        result=run[\"result\"],\n",
    "        path=Path(run[\"path\"]),\n",
    "        stats=run[\"stats\"],\n",
    "        stats_no_reductions=run[\"stats_no_reductions\"],\n",
    "    ) for run in runs]\n",
    "\n",
    "\n",
    "def get_random_instance(unsat_only: bool = True):\n",
    "    while True:\n",
    "        run = random.choice(runs)\n",
    "        if not unsat_only or not run.result:\n",
    "            return run"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:12:23.992550Z",
     "start_time": "2024-12-06T18:12:23.988111Z"
    }
   },
   "source": [
    "class CadicalEnv:\n",
    "    def __init__(\n",
    "        self,\n",
    "        cadical_path: Path,\n",
    "        num_parallel: int = 2,\n",
    "        runs_per_episode: int = 16,\n",
    "    ):\n",
    "        self.cadical_path = cadical_path\n",
    "        self.num_parallel = num_parallel\n",
    "        self.runs_per_episode = runs_per_episode\n",
    "        self.semaphore = asyncio.Semaphore(num_parallel)\n",
    "\n",
    "    async def run_instance(self, agent: Agent, instance_path: Path) -> EpisodeResult:\n",
    "        result = EpisodeResult.empty()\n",
    "        router = runner.Router()\n",
    "\n",
    "        reduce_number = 0\n",
    "\n",
    "        @router.route(\"reduce\")\n",
    "        async def _reduce_route(conn: runner.Connection, info: runner.RunInfo, _data):\n",
    "            nonlocal reduce_number\n",
    "\n",
    "            logger.info(\"Received clause database reduction\")\n",
    "\n",
    "            num_vars = await conn.read_u64()\n",
    "            levels = [-1] * num_vars\n",
    "            vals = [-1] * num_vars\n",
    "            for i in range(num_vars):\n",
    "                vals[i] = await conn.read_i8()\n",
    "                levels[i] = await conn.read_i32()\n",
    "            num_clauses = await conn.read_u64()\n",
    "            clauses = [await conn.read_clause() for _ in range(num_clauses)]\n",
    "            num_reducible = await conn.read_u64()\n",
    "            num_target = await conn.read_u64()\n",
    "            reducible_ids = [await conn.read_u64() for _ in range(num_reducible)]\n",
    "            conflicts = await conn.read_u64()\n",
    "\n",
    "            if reduce_number != 0:\n",
    "                result.add_reward(-conflicts * HP.penalty_per_conflict)\n",
    "\n",
    "            problem = ReductionProblem(\n",
    "                num_vars=num_vars,\n",
    "                levels=levels,\n",
    "                vals=vals,\n",
    "                clauses=clauses,\n",
    "                reducible_ids=reducible_ids,\n",
    "            )\n",
    "\n",
    "            logger.debug(\"Finished reading reduction data\")\n",
    "\n",
    "            cnf, dim_info = problem_to_cnf_graph(problem)\n",
    "            assert dim_info == DIM_INFO\n",
    "            \n",
    "            ex = float(num_target)\n",
    "\n",
    "            logger.debug(\"Converted problem to CNF graph\")\n",
    "\n",
    "            dist, value = agent.act(cnf, ex)\n",
    "            action = dist.sample()\n",
    "\n",
    "            logger.debug(\"Agent acted\")\n",
    "\n",
    "            result.add(\n",
    "                state=(cnf, ex),\n",
    "                dist=dist,\n",
    "                action=action,\n",
    "                reward=None,\n",
    "                value=value,\n",
    "            )\n",
    "\n",
    "            reducible_ids = ordered_reducible_ids(problem)\n",
    "\n",
    "            to_reduces = []\n",
    "            for id_, a in zip(reducible_ids, action):\n",
    "                if a > 0.5:\n",
    "                    to_reduces.append(id_)\n",
    "\n",
    "            logger.debug(\"Results are written to replay buffer\")\n",
    "            logger.debug(\"Sending reduction data\")\n",
    "\n",
    "            await conn.write_u32(len(to_reduces))\n",
    "            for id_ in to_reduces:\n",
    "                await conn.write_u64(id_)\n",
    "\n",
    "            reduce_number += 1\n",
    "\n",
    "        @router.route(\"stats\")\n",
    "        async def _stats_route(conn: runner.Connection, info: runner.RunInfo, data):\n",
    "            logger.info(\"Received stats\")\n",
    "            stats = {}\n",
    "            while (name := await conn.read_str()) != \"end\":\n",
    "                if name == \"time\":\n",
    "                    stats[name] = await conn.read_f64()\n",
    "                else:\n",
    "                    stats[name] = await conn.read_u64()\n",
    "            await conn.write_ok()\n",
    "            result.add_reward(-stats[\"conflicts\"] * HP.penalty_per_conflict)\n",
    "            result.complete(stats)\n",
    "\n",
    "        await runner.run_instance(\n",
    "            self.cadical_path,\n",
    "            [\"--reduce-mode\", \"2\"],\n",
    "            instance_path,\n",
    "            router.routes,\n",
    "            silent=True,\n",
    "            semaphore=self.semaphore,\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "\n",
    "    async def run_episode(self, agent: Agent) -> EpisodeResult:\n",
    "        tasks = []\n",
    "        for _ in range(self.runs_per_episode):\n",
    "            instance = get_random_instance()\n",
    "            tasks.append(self.run_instance(agent, instance.path))\n",
    "\n",
    "        await asyncio.gather(*tasks)\n",
    "        return EpisodeResult.merge_all(results)\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:14:27.746732Z",
     "start_time": "2024-12-06T18:12:44.046597Z"
    }
   },
   "source": [
    "model = CnfGraphModel(\n",
    "    input_global_dim=DIM_INFO.num_global_features,\n",
    "    input_variable_dim=DIM_INFO.num_var_features,\n",
    "    input_clause_dim=DIM_INFO.num_clause_features,\n",
    "    edge_dim=DIM_INFO.num_edge_features,\n",
    "    hidden_dims=[32, 32, 32, 32],\n",
    ")\n",
    "\n",
    "agent = Agent(model)\n",
    "\n",
    "env = CadicalEnv(\n",
    "    Path(\"../cadical/build/cadical\"),\n",
    "    num_parallel=2,\n",
    "    runs_per_episode=16,\n",
    ")\n",
    "\n",
    "for episode in range(100):\n",
    "    print(f\"Episode {episode}: \", end=\"\")\n",
    "    results = await env.run_episode(agent)\n",
    "    agent.update(results)\n",
    "    print(f\"Rewards: {sum(results.rewards)}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/snap/pycharm-professional/440/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_collect_try_except_info.py:153: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  if not hasattr(co, 'co_lnotab'):\n",
      "INFO:runner:Running ../cadical/build/cadical on /home/elt/projects/sat-rl-exploration/instances/unif-6f79bec5-88c4-43e4-b475-da37bb281928.cnf\n",
      "INFO:runner:Running /home/elt/projects/sat-rl-exploration/py/../cadical/build/cadical --reduce-mode 2 --socket /tmp/77b0277c-d6d1-4963-9e91-7c5d1e141473.sock -t 0 /home/elt/projects/sat-rl-exploration/instances/unif-6f79bec5-88c4-43e4-b475-da37bb281928.cnf\n",
      "INFO:runner:Running ../cadical/build/cadical on /home/elt/projects/sat-rl-exploration/instances/unif-4abf4c90-2b4a-4957-b932-181b65b6b9e2.cnf\n",
      "INFO:runner:Running /home/elt/projects/sat-rl-exploration/py/../cadical/build/cadical --reduce-mode 2 --socket /tmp/aad1bd2f-d365-4d95-8cb7-89c97dac3186.sock -t 0 /home/elt/projects/sat-rl-exploration/instances/unif-4abf4c90-2b4a-4957-b932-181b65b6b9e2.cnf\n",
      "DEBUG:runner:Starting connection to /tmp/77b0277c-d6d1-4963-9e91-7c5d1e141473.sock\n",
      "DEBUG:runner:Starting connection to /tmp/aad1bd2f-d365-4d95-8cb7-89c97dac3186.sock\n",
      "DEBUG:runner:Server started\n",
      "DEBUG:runner:Server started\n",
      "/snap/pycharm-professional/440/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_collect_try_except_info.py:153: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  if not hasattr(co, 'co_lnotab'):\n",
      "DEBUG:runner:Connection established\n",
      "/snap/pycharm-professional/440/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_collect_try_except_info.py:153: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  if not hasattr(co, 'co_lnotab'):\n",
      "DEBUG:runner:Connection established\n",
      "INFO:notebook:Received clause database reduction\n",
      "INFO:notebook:Received clause database reduction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:notebook:Finished reading reduction data\n",
      "INFO:notebook:Converting problem to CNF graph\n",
      "INFO:notebook:Finished converting problem to CNF graph\n",
      "DEBUG:notebook:Converted problem to CNF graph\n",
      "INFO:notebook:Running agent act\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Finished agent act\n",
      "DEBUG:notebook:Finished reading reduction data\n",
      "INFO:notebook:Converting problem to CNF graph\n",
      "INFO:notebook:Finished converting problem to CNF graph\n",
      "DEBUG:notebook:Converted problem to CNF graph\n",
      "INFO:notebook:Running agent act\n",
      "INFO:notebook:Starting model forward pass\n",
      "INFO:notebook:Finished model forward pass\n",
      "INFO:notebook:Finished agent act\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCancelledError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m episode \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m):\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpisode \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepisode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 19\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m env\u001B[38;5;241m.\u001B[39mrun_episode(agent)\n\u001B[1;32m     20\u001B[0m     agent\u001B[38;5;241m.\u001B[39mupdate(results)\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRewards: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28msum\u001B[39m(results\u001B[38;5;241m.\u001B[39mrewards)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[37], line 117\u001B[0m, in \u001B[0;36mCadicalEnv.run_episode\u001B[0;34m(self, agent)\u001B[0m\n\u001B[1;32m    114\u001B[0m     instance \u001B[38;5;241m=\u001B[39m get_random_instance()\n\u001B[1;32m    115\u001B[0m     tasks\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_instance(agent, instance\u001B[38;5;241m.\u001B[39mpath))\n\u001B[0;32m--> 117\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39mgather(\u001B[38;5;241m*\u001B[39mtasks)\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m EpisodeResult\u001B[38;5;241m.\u001B[39mmerge_all(results)\n",
      "Cell \u001B[0;32mIn[37], line 100\u001B[0m, in \u001B[0;36mCadicalEnv.run_instance\u001B[0;34m(self, agent, instance_path)\u001B[0m\n\u001B[1;32m     97\u001B[0m     result\u001B[38;5;241m.\u001B[39madd_reward(\u001B[38;5;241m-\u001B[39mstats[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconflicts\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m*\u001B[39m HP\u001B[38;5;241m.\u001B[39mpenalty_per_conflict)\n\u001B[1;32m     98\u001B[0m     result\u001B[38;5;241m.\u001B[39mcomplete(stats)\n\u001B[0;32m--> 100\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m runner\u001B[38;5;241m.\u001B[39mrun_instance(\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcadical_path,\n\u001B[1;32m    102\u001B[0m     [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--reduce-mode\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    103\u001B[0m     instance_path,\n\u001B[1;32m    104\u001B[0m     router\u001B[38;5;241m.\u001B[39mroutes,\n\u001B[1;32m    105\u001B[0m     silent\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    106\u001B[0m     semaphore\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msemaphore,\n\u001B[1;32m    107\u001B[0m )\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/projects/sat-rl-exploration/py/runner.py:216\u001B[0m, in \u001B[0;36mrun_instance\u001B[0;34m(solver, args, cnf_path, routes, silent, timeout_seconds, data, semaphore, valgrind)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_instance\u001B[39m(\n\u001B[1;32m    205\u001B[0m     solver: Path,\n\u001B[1;32m    206\u001B[0m     args: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    214\u001B[0m     valgrind: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    215\u001B[0m ):\n\u001B[0;32m--> 216\u001B[0m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mwith\u001B[39;00m semaphore \u001B[38;5;28;01mif\u001B[39;00m semaphore \u001B[38;5;28;01melse\u001B[39;00m contextlib\u001B[38;5;241m.\u001B[39mnullcontext():\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m solver\u001B[38;5;241m.\u001B[39mexists(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msolver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not exist\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m cnf_path\u001B[38;5;241m.\u001B[39mexists(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcnf_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not exist\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/asyncio/locks.py:14\u001B[0m, in \u001B[0;36m_ContextManagerMixin.__aenter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__aenter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39macquire()\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;66;03m# We have no use for the \"as ...\"  clause in the with\u001B[39;00m\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;66;03m# statement for locks.\u001B[39;00m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/asyncio/locks.py:386\u001B[0m, in \u001B[0;36mSemaphore.acquire\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    384\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    385\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 386\u001B[0m         \u001B[38;5;28;01mawait\u001B[39;00m fut\n\u001B[1;32m    387\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    388\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_waiters\u001B[38;5;241m.\u001B[39mremove(fut)\n",
      "\u001B[0;31mCancelledError\u001B[0m: "
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
